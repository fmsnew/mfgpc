{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('error', category=UserWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import utils_2019\n",
    "import mfgpc_opt as mfgpc\n",
    "from utilities_new import SSMF, MajorClassClassifier, safe_roc_auc_score, get_binary_dataset\n",
    "import utils_hetmogp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'ROCAUC': lambda clf, X, y: safe_roc_auc_score(y, clf.predict_proba(X)[:, 1]), \n",
    "           'Accuracy': lambda clf, X, y: accuracy_score(y, clf.predict(X))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1, constant_value_bounds=(0.1, 10.0)) * RBF(1, length_scale_bounds=(0.01, 10))\n",
    "mf_gpc = mfgpc.MultiFidelityGaussianProcessClassifier(kernel = kernel, rho = 0.0, n_restarts_optimizer = 10, eval_gradient=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {}\n",
    "methods['ss_gpc'] = make_pipeline(StandardScaler(), GaussianProcessClassifier(kernel=kernel, n_restarts_optimizer=10))\n",
    "methods['ss_mf_gpc'] = SSMF(mf_gpc)\n",
    "methods['ss_logit'] = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "methods['xgb'] = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.05, subsample=0.85)\n",
    "methods['major_vote'] = MajorClassClassifier()\n",
    "#methods['hetmogp'] = SSMF(utils_hetmogp.HetmogpWrapeper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {}\n",
    "methods['hetmogp'] = SSMF(utils_hetmogp.HetmogpWrapeper(M=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for ID in range(0, 40):\n",
    "    artdf = pd.read_csv('Datasets/artifitial/df_' + str(ID) + '.csv')\n",
    "    X = artdf[list(filter(lambda x: x.find('feature') != -1, artdf.columns))].values\n",
    "    y_gold = artdf['target_gold'].values\n",
    "    full_dfs = []\n",
    "    for c in [0.2, 0.4]:\n",
    "        y_corrupted = artdf['taget_noisy_' + str(c)].values\n",
    "        hf_dfs = []\n",
    "        for hf in [75]:\n",
    "            print(ID, c, hf)\n",
    "            kwargs = {\n",
    "              'X':X, \n",
    "              'y_lf':y_corrupted, \n",
    "              'y_hf':y_gold, \n",
    "              'y_groundtruth':y_gold, \n",
    "              'scoring':scoring,\n",
    "              'test_size':2500, \n",
    "              'train_lf_size':hf*3, \n",
    "              'train_hf_size':hf, \n",
    "              'runs':3, \n",
    "              'verbose':True\n",
    "            }\n",
    "            #df = utils_2019.make_test_results_df(methods['ss_gpc'], 'ss_gpc', 'high-fidelity', kwargs)\n",
    "            df = utils_2019.run_tests_all_clfs(methods, **kwargs)\n",
    "            \n",
    "            #assert False\n",
    "            \n",
    "            df['hf'] = hf\n",
    "            hf_dfs.append(df)\n",
    "        dfs = pd.concat(hf_dfs, ignore_index=True)\n",
    "        dfs['noise'] = c\n",
    "        full_dfs.append(dfs)\n",
    "    full_dfs = pd.concat(full_dfs, ignore_index=True)\n",
    "    full_dfs.to_csv('loggers/artifitial_baselines/2019_df_' + str(ID) + '_basic.csv', index=False)\n",
    "    print(ID, ('%.1f' % ((time.time() - start_time)/60)) + ' min passed')\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = ['diabetes', 'german', 'satimage-1', 'mushroom', 'splice', 'spambase', 'hypothyroid', 'waveform-40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alias in aliases:\n",
    "    X, y = get_binary_dataset(alias)\n",
    "    print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for alias in aliases:\n",
    "    X, y = get_binary_dataset(alias)\n",
    "    full_dfs = []\n",
    "    for c in [0.2, 0.4]:\n",
    "        np.random.seed(0)\n",
    "        y_corrupted = (y + (np.random.rand(len(y)) < c).astype(int)) % 2\n",
    "        #raise Exception\n",
    "        hf_dfs = []\n",
    "        \n",
    "        for hf in tqdm([75]):\n",
    "            kwargs = {\n",
    "              'X':X, \n",
    "              'y_lf':y_corrupted, \n",
    "              'y_hf':y, \n",
    "              'y_groundtruth':y, \n",
    "              'scoring':scoring,\n",
    "              'test_size':len(X) - hf*3 - 1, \n",
    "              'train_lf_size':hf*3, \n",
    "              'train_hf_size':hf, \n",
    "              'runs':3, \n",
    "              'verbose':True\n",
    "            }\n",
    "            df = utils_2019.run_tests_all_clfs(methods, **kwargs)\n",
    "            df['hf'] = hf\n",
    "            hf_dfs.append(df)\n",
    "        dfs = pd.concat(hf_dfs, ignore_index=True)\n",
    "        dfs['noise'] = c\n",
    "        full_dfs.append(dfs)\n",
    "    full_dfs = pd.concat(full_dfs, ignore_index=True)\n",
    "    full_dfs.to_csv('loggers/artifitial_baselines/2019_df_' + alias + '_basic.csv', index=False)\n",
    "    print(alias, ('%.1f' % ((time.time() - start_time)/60)) + ' min passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# musicgenre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_vote(series):\n",
    "    return series.value_counts().index[0]\n",
    "\n",
    "def random_vote(series):\n",
    "    return series.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Datasets/mturk-datasets/music_genre_classification/music_genre_gold.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_encoder = {}\n",
    "classes = data['class'].value_counts()\n",
    "for i in range(len(classes)):\n",
    "    class_encoder[classes.index[i]] = i\n",
    "class_decoder = {v:k for k, v in class_encoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mturk = pd.read_csv('Datasets/mturk-datasets/music_genre_classification/music_genre_mturk.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mturk['class_code'] = data_mturk['class'].map(class_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mturk_majority = data_mturk[['id', 'class']].groupby('id').agg(major_vote).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mturk_majority.columns = ['id', 'hf_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data = pd.merge(data, data_mturk_majority, left_on = 'id', right_on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "data_mturk_random = data_mturk[['id', 'class']].groupby('id').agg(random_vote).reset_index()\n",
    "data_mturk_random.columns = ['id', 'lf_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_data = pd.merge(hf_data, data_mturk_random, left_on = 'id', right_on = 'id', how = 'inner')\n",
    "\n",
    "mf_data['class_code'] = mf_data['class'].map(class_encoder)\n",
    "mf_data['hf_class_code'] = mf_data['hf_class'].map(class_encoder)\n",
    "mf_data['lf_class_code'] = mf_data['lf_class'].map(class_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda x: x.find('feature') != -1, data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_genre in class_encoder.values():\n",
    "    X = mf_data[features].values\n",
    "    y = mf_data['hf_class_code'].apply(lambda x: int(x == target_genre)).values\n",
    "    y_corrupted = mf_data['lf_class_code'].apply(lambda x: int(x == target_genre)).values\n",
    "    y_gold = mf_data['class_code'].apply(lambda x: int(x == target_genre)).values\n",
    "\n",
    "    hf_dfs = []\n",
    "    for hf in [75]:\n",
    "        print(target_genre, hf)\n",
    "        kwargs = {\n",
    "              'X':X, \n",
    "              'y_lf':y_corrupted, \n",
    "              'y_hf':y, \n",
    "              'y_groundtruth':y_gold, \n",
    "              'scoring':scoring,\n",
    "              'test_size':len(X) - hf*3 - 1, \n",
    "              'train_lf_size':hf*3, \n",
    "              'train_hf_size':hf, \n",
    "              'runs':3, \n",
    "              'verbose':True\n",
    "            }\n",
    "        df = utils_2019.run_tests_all_clfs(methods, **kwargs)\n",
    "        df['hf'] = hf\n",
    "        hf_dfs.append(df)\n",
    "    dfs = pd.concat(hf_dfs, ignore_index=True)\n",
    "    dfs.to_csv('loggers/artifitial_baselines/2019_df_' + 'musicgenre_' + class_decoder[target_genre] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentimentpolarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mturk = pd.read_csv('Datasets/mturk-datasets/sentiment_polarity/polarity_mturk_lsa_topics.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data = data_mturk[['id', 'class']].groupby('id').agg(major_vote)\n",
    "hf_data.columns = ['class_hf']\n",
    "\n",
    "lf_data = data_mturk[['id', 'class']].groupby('id').agg(random_vote)\n",
    "lf_data.columns = ['class_lf']\n",
    "\n",
    "tmp = pd.merge(hf_data, lf_data, left_index=True, right_index=True)\n",
    "\n",
    "(tmp['class_hf'] == tmp['class_lf']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Datasets/mturk-datasets/sentiment_polarity/polarity_gold_lsa_topics.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, tmp, left_on='id', right_index=True, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[list(filter(lambda x: x.find('TOPIC') != -1, data.columns))].values\n",
    "y = (data['class_hf'].values == 'pos').astype(int)\n",
    "y_corrupted = (data['class_lf'].values == 'pos').astype(int)\n",
    "y_gold = (data['class'].values == 'pos').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dfs = []\n",
    "for hf in [75]:\n",
    "    print(target_genre, hf)\n",
    "    kwargs = {\n",
    "          'X':X, \n",
    "          'y_lf':y_corrupted, \n",
    "          'y_hf':y, \n",
    "          'y_groundtruth':y_gold, \n",
    "          'scoring':scoring,\n",
    "          'test_size':len(X) - hf*3 - 1, \n",
    "          'train_lf_size':hf*3, \n",
    "          'train_hf_size':hf, \n",
    "          'runs':3*5, \n",
    "          'verbose':True\n",
    "        }\n",
    "    df = utils_2019.run_tests_all_clfs(methods, **kwargs)\n",
    "    df['hf'] = hf\n",
    "    hf_dfs.append(df)\n",
    "dfs = pd.concat(hf_dfs, ignore_index=True)\n",
    "dfs.to_csv('loggers/artifitial_baselines/2019_df_sentimentpolarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
