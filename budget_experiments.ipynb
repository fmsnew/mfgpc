{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('error', category=UserWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import utils_2019\n",
    "import mfgpc_opt as mfgpc\n",
    "from utilities_new import SSMF, MajorClassClassifier, safe_roc_auc_score, get_binary_dataset\n",
    "import utils_hetmogp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'ROCAUC': lambda clf, X, y: safe_roc_auc_score(y, clf.predict_proba(X)[:, 1]), \n",
    "           'Accuracy': lambda clf, X, y: accuracy_score(y, clf.predict(X))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1, constant_value_bounds=(0.1, 10.0)) * RBF(1, length_scale_bounds=(0.01, 10))\n",
    "mf_gpc = mfgpc.MultiFidelityGaussianProcessClassifier(kernel = kernel, rho = 0.0, n_restarts_optimizer = 10, eval_gradient=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_mf = {}\n",
    "methods_mf['ss_mf_gpc'] = SSMF(mf_gpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_sf = {}\n",
    "methods_sf['ss_gpc'] = make_pipeline(StandardScaler(), GaussianProcessClassifier(kernel=kernel, n_restarts_optimizer=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lf_cost, hf_cost in [(1, 8), (2, 8), (4, 8)]:\n",
    "    for hf_budget_ratio in [0., 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        hf = int(np.round(BUDGET * hf_budget_ratio / hf_cost))\n",
    "        lf = int(np.round(BUDGET * (1 - hf_budget_ratio) / lf_cost))\n",
    "        print(hf_cost, lf_cost, hf_budget_ratio, hf, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "#for ID in range(0, 40, 5):\n",
    "for ID in range(1, 40, 5):\n",
    "    artdf = pd.read_csv('Datasets/artifitial/df_' + str(ID) + '.csv')\n",
    "    X = artdf[list(filter(lambda x: x.find('feature') != -1, artdf.columns))].values\n",
    "    y_gold = artdf['target_gold'].values\n",
    "    full_dfs = []\n",
    "    for c in [0.0, 0.2, 0.3, 0.4]:\n",
    "        y_corrupted = artdf['taget_noisy_' + str(c)].values\n",
    "        hf_dfs = []\n",
    "        for lf_cost, hf_cost in [(1, 8), (2, 8), (4, 8)]:\n",
    "            for hf_budget_ratio in [0., 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "                hf = int(BUDGET * hf_budget_ratio / hf_cost)\n",
    "                lf = int(BUDGET * (1 - hf_budget_ratio) / lf_cost)\n",
    "                \n",
    "                print(ID, c, lf_cost, hf_cost, hf_budget_ratio, hf, lf)\n",
    "                kwargs = {\n",
    "                  'X':X, \n",
    "                  'y_lf':y_corrupted, \n",
    "                  'y_hf':y_gold, \n",
    "                  'y_groundtruth':y_gold, \n",
    "                  'scoring':scoring,\n",
    "                  'test_size':2500, \n",
    "                  'train_lf_size':lf, \n",
    "                  'train_hf_size':hf, \n",
    "                  'runs':3, \n",
    "                  'verbose':True\n",
    "                }\n",
    "                \n",
    "                if hf_budget_ratio == 0:\n",
    "                    kwargs['train_hf_size'] = lf\n",
    "                    kwargs['y_hf'] = y_corrupted # low fidelity instead of high fidelity\n",
    "                    \n",
    "                if hf_budget_ratio == 0 or hf_budget_ratio == 1:\n",
    "                    kwargs['modes'] = ['high-fidelity']\n",
    "                    df = utils_2019.run_tests_all_clfs(methods_sf, **kwargs)\n",
    "                else:\n",
    "                    kwargs['modes'] = ['stacking']\n",
    "                    df = utils_2019.run_tests_all_clfs(methods_mf, **kwargs)\n",
    "                \n",
    "                #assert False\n",
    "\n",
    "                df['hf_cost'] = hf_cost\n",
    "                df['lf_cost'] = lf_cost\n",
    "                df['hf_budget_ratio'] = hf_budget_ratio\n",
    "                df['hf'] = hf\n",
    "                df['lf'] = lf\n",
    "                \n",
    "                hf_dfs.append(df)\n",
    "        dfs = pd.concat(hf_dfs, ignore_index=True)\n",
    "        dfs['noise'] = c\n",
    "        full_dfs.append(dfs)\n",
    "    full_dfs = pd.concat(full_dfs, ignore_index=True)\n",
    "    full_dfs.to_csv('loggers/artifitial_baselines/2019_df_' + str(ID) + '_budget.csv', index=False)\n",
    "    print(ID, ('%.1f' % ((time.time() - start_time)/60)) + ' min passed')\n",
    "    #break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
